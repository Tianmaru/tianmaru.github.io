---
layout: post
title:  "Hello World!"
date:   2024-02-04
---

Hello world and welcome to my website!
I am a PhD student researching machine learning methods and occasionally losing myself in the rabbit hole that is Bayesian statistics.
In Deep Learning, *Catastrophic Forgetting* refers to the phenomenon, that the performance of fitted models starts to rapidly deteriorate as soon as they are trained for a new task.
The artificial neural networks "forget" how they handled the previous task, due to important neural connections getting overridden.
In a time where everyone's replacement by a soulless artificial intelligence seems to be looming just around the corner, catastrophic forgetting reassuringly renders machine learning models familiarly human.
Maybe, the final sci-fi battle between man and robot will not be decided by who can learn faster, but who can forget slower.
To at least avoid forgetting everything I learned, please allow me to share it with you in this blog!

